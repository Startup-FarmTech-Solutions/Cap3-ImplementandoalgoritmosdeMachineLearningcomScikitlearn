# Cap3-ImplementandoalgoritmosdeMachineLearningcomScikitlearn
A classificaÃ§Ã£o de grÃ£os Ã© uma etapa fundamental no controle de qualidade dentro da cadeia produtiva agrÃ­cola. Atualmente, em muitas cooperativas de pequeno e mÃ©dio porte, esse processo ainda Ã© realizado de forma manual por especialistas, utilizando inspeÃ§Ã£o visual e ferramentas simples.

---

# ğŸŒ¾ **Projeto: Da Terra ao CÃ³digo â€” Automatizando a ClassificaÃ§Ã£o de GrÃ£os com Machine Learning**

---

## ğŸ“„ **DescriÃ§Ã£o do Projeto**

A classificaÃ§Ã£o de grÃ£os Ã© uma etapa fundamental no controle de qualidade dentro da cadeia produtiva agrÃ­cola. Atualmente, em muitas cooperativas de pequeno e mÃ©dio porte, esse processo ainda Ã© realizado de forma manual por especialistas, utilizando inspeÃ§Ã£o visual e ferramentas simples. Isso gera desafios como alta demanda de tempo, custos operacionais elevados e possÃ­veis erros humanos, afetando diretamente a eficiÃªncia e a qualidade do produto final.

Este projeto tem como foco o desenvolvimento de um sistema inteligente capaz de realizar a **classificaÃ§Ã£o automÃ¡tica de grÃ£os de trigo** com base em suas caracterÃ­sticas fÃ­sicas. A soluÃ§Ã£o utiliza algoritmos de **Machine Learning** aplicados ao **"Seeds Dataset"** do UCI Machine Learning Repository, com amostras de trÃªs tipos de trigo: **Kama, Rosa e Canadian**.

AlÃ©m do desenvolvimento dos modelos, serÃ¡ criado um **dashboard interativo utilizando Streamlit**, que permitirÃ¡ que qualquer usuÃ¡rio â€” mesmo sem conhecimento tÃ©cnico â€” possa realizar classificaÃ§Ãµes, visualizar anÃ¡lises e extrair informaÃ§Ãµes Ãºteis sobre os grÃ£os analisados.

---

## âœ… **Justificativa**

O desenvolvimento deste projeto se justifica pela necessidade crescente de **automatizar processos agrÃ­colas**, tornando-os mais precisos, eficientes e acessÃ­veis, especialmente para pequenos produtores e cooperativas.

### ğŸ’¡ **Por que Ã© necessÃ¡rio?**

* Processos manuais estÃ£o sujeitos a erros e inconsistÃªncias.
* Reduz o custo com mÃ£o de obra especializada.
* Aumenta a produtividade e padronizaÃ§Ã£o na classificaÃ§Ã£o.
* Traz acessibilidade Ã  tecnologia de anÃ¡lise de dados no campo.

### ğŸŒ **Impacto Esperado**

* ModernizaÃ§Ã£o das prÃ¡ticas agrÃ­colas.
* ReduÃ§Ã£o de custos operacionais.
* Tomada de decisÃ£o mais assertiva.
* ContribuiÃ§Ã£o para a transformaÃ§Ã£o digital no agronegÃ³cio.

---

## ğŸ¯ **Objetivos**

### ğŸ”¹ **Objetivo Geral**

Desenvolver uma soluÃ§Ã£o baseada em Machine Learning capaz de classificar grÃ£os de trigo automaticamente a partir de suas caracterÃ­sticas fÃ­sicas, utilizando um dashboard interativo para facilitar a utilizaÃ§Ã£o pelos usuÃ¡rios.

### ğŸ”¸ **Objetivos EspecÃ­ficos**

* Realizar anÃ¡lise exploratÃ³ria e prÃ©-processamento dos dados.
* Implementar e comparar diferentes modelos de classificaÃ§Ã£o.
* Otimizar os modelos para aumentar a acurÃ¡cia e a robustez.
* Avaliar os modelos utilizando mÃ©tricas como acurÃ¡cia, precisÃ£o, recall, F1-score e matriz de confusÃ£o.
* Desenvolver um dashboard interativo que permita a utilizaÃ§Ã£o do modelo de classificaÃ§Ã£o.
* Documentar todo o processo no GitHub com cÃ³digo, relatÃ³rios e arquivos auxiliares.

---

## ğŸ”¬ **Metodologia â€” CRISP-DM**

O projeto segue as etapas da metodologia **CRISP-DM (Cross Industry Standard Process for Data Mining)**, amplamente utilizada para desenvolvimento de projetos de ciÃªncia de dados.

### ğŸš¦ **Etapas:**

1. **Entendimento do NegÃ³cio**

#### Fluxo de Dados

1. O dataset original estÃ¡ em formato `.txt`.
2. Os dados serÃ£o carregados em memÃ³ria com `pandas` para prÃ©-processamento.
3. ApÃ³s o tratamento, o dataset limpo serÃ¡ salvo em `.csv`.
4. Os dados tratados serÃ£o usados para:
   - Treinamento de modelos de Machine Learning.
   - AnÃ¡lises estatÃ­sticas.
   - VisualizaÃ§Ãµes.

#### Estrutura de Dados

| Coluna | DescriÃ§Ã£o |
|--------|----------|
| area | Ãrea da semente |
| perimeter | PerÃ­metro |
| compactness | Compacidade |
| kernel_length | Comprimento do grÃ£o |
| kernel_width | Largura do grÃ£o |
| asymmetry | Coeficiente de assimetria |
| kernel_groove | Comprimento do sulco do grÃ£o |
| class | Classe (1, 2 ou 3) |

#### Armazenamento

- **Dados brutos**: txt
- **Dados tratados**: txt limpo
- **Modelos**: arquivos `.pkl` ou similares
- **Resultados**: 

#### Banco de Dados

- Decidiu-se utilizar **txt** como estrutura de armazenamento.


2. **Entendimento dos Dados**

   * AnÃ¡lise do dataset "Seeds Dataset".
   * CompreensÃ£o das variÃ¡veis:

     * Ãrea, PerÃ­metro, Compacidade, Comprimento do NÃºcleo, Largura do NÃºcleo, Coeficiente de Assimetria, Comprimento do Sulco.

3. **PreparaÃ§Ã£o dos Dados**

   * VerificaÃ§Ã£o de valores ausentes.
   * DetecÃ§Ã£o e tratamento de outliers.
   * NormalizaÃ§Ã£o ou padronizaÃ§Ã£o dos dados.
   * CriaÃ§Ã£o de visualizaÃ§Ãµes (boxplots, histogramas, scatterplots, heatmap de correlaÃ§Ã£o).

4. ## ğŸ“ˆ Machine Learning

###  Escolha e AvaliaÃ§Ã£o de Algoritmos

Para esta fase do projeto, decidimos realizar o **treinamento e avaliaÃ§Ã£o com mÃºltiplos algoritmos** de Machine Learning, com o objetivo de identificar aquele que oferece o melhor desempenho para o problema de **prever a necessidade de irrigaÃ§Ã£o**.

O problema foi modelado como uma **classificaÃ§Ã£o binÃ¡ria**, onde o modelo deve prever se a irrigaÃ§Ã£o Ã© necessÃ¡ria (`1`) ou nÃ£o (`0`), com base em variÃ¡veis como umidade do solo, nÃ­veis de nutrientes, temperatura e hora do dia.

---

### Algoritmos Avaliados

| Algoritmo                                  | Vantagens                                                              | Desvantagens                                              |
| ------------------------------------------ | ---------------------------------------------------------------------- | --------------------------------------------------------- |
| **Logistic Regression**                    | Simples, rÃ¡pido, bom para baseline                                     | SupÃµe relaÃ§Ã£o linear entre as variÃ¡veis                   |
| **Decision Tree**                          | FÃ¡cil de interpretar, lida com variÃ¡veis categÃ³ricas                   | Pode sofrer de overfitting e ser sensÃ­vel a ruÃ­do         |
| **Random Forest**                          | Reduz overfitting, boa acurÃ¡cia, robusto                               | Mais lento e menos interpretÃ¡vel que uma Ã¡rvore Ãºnica     |
| **K-Nearest Neighbors (KNN)**              | Simples, nÃ£o-paramÃ©trico, intuitivo                                    | Custo computacional elevado em grandes conjuntos de dados |
| **Support Vector Machine (SVM)**           | Eficaz em espaÃ§os de alta dimensÃ£o, bom para problemas complexos       | Mais lento e exige ajuste cuidadoso de parÃ¢metros         |
| **Gradient Boosting (LightGBM, CatBoost)** | Alta performance, lida bem com nÃ£o-linearidades e dados desbalanceados | Complexidade maior e menos interpretÃ¡vel                  |

---

### Metodologia

Todos os algoritmos foram treinados utilizando a biblioteca **Scikit-learn** (com exceÃ§Ã£o do **LightGBM** e **CatBoost**, implementados com suas respectivas bibliotecas).

O dataset foi dividido em **80% para treino** e **20% para teste** utilizando **stratified split** para manter a proporÃ§Ã£o das classes.

O prÃ©-processamento incluiu:

* NormalizaÃ§Ã£o das variÃ¡veis numÃ©ricas para algoritmos sensÃ­veis a escala (KNN, SVM).
* ConversÃ£o de variÃ¡veis categÃ³ricas, se houver.
* Tratamento de dados ausentes.

---

### MÃ©tricas de AvaliaÃ§Ã£o

Para comparar os modelos, utilizamos as seguintes mÃ©tricas:

| MÃ©trica                | Justificativa                                                |
| ---------------------- | ------------------------------------------------------------ |
| **AcurÃ¡cia**           | Percentual de acertos gerais                                 |
| **PrecisÃ£o**           | Evitar falsos positivos: irrigar desnecessariamente          |
| **Recall**             | Evitar falsos negativos: falhar em irrigar quando necessÃ¡rio |
| **F1-Score**           | MÃ©trica principal para balancear precisÃ£o e recall           |
| **Matriz de ConfusÃ£o** | AnÃ¡lise visual dos erros de cada modelo                      |

**Obs.:** Se o dataset apresentar **desbalanceamento** entre classes, as mÃ©tricas como **F1-Score** e **Recall** terÃ£o maior peso na decisÃ£o final.

---

### Processo de Treinamento

Para cada modelo, seguimos o mesmo pipeline:

1. SeparaÃ§Ã£o de **features** e **target**.
2. DivisÃ£o em **treino** e **teste**.
3. Ajuste de **parÃ¢metros padrÃ£o** (sem hiperparÃ¢metros complexos, para avaliaÃ§Ã£o justa).
4. Treinamento do modelo.
5. AvaliaÃ§Ã£o com as mÃ©tricas definidas.

---

### Exemplo de CÃ³digo para AvaliaÃ§Ã£o de Todos os Modelos

```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC

import lightgbm as lgb
from catboost import CatBoostClassifier

# SeparaÃ§Ã£o
X = df[['umidade', 'nutrientes', 'temperatura', 'hora_dia']]
y = df['precisa_irrigar']

# DivisÃ£o
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# NormalizaÃ§Ã£o
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Modelos
models = {
    'Logistic Regression': LogisticRegression(),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'KNN': KNeighborsClassifier(),
    'SVM': SVC(probability=True),
    'LightGBM': lgb.LGBMClassifier(),
    'CatBoost': CatBoostClassifier(verbose=0)
}

# Treinamento e avaliaÃ§Ã£o
for name, model in models.items():
    if name in ['KNN', 'SVM', 'Logistic Regression']:
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
    else:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

    print(f"\nModelo: {name}")
    print(classification_report(y_test, y_pred))
    print("Matriz de ConfusÃ£o:")
    print(confusion_matrix(y_test, y_pred))
```

---

###  DefiniÃ§Ã£o do Algoritmo Final

ApÃ³s realizar a avaliaÃ§Ã£o com todos os modelos e comparar os resultados com base nas mÃ©tricas definidas, selecionaremos como **algoritmo final** aquele que apresentar o **melhor equilÃ­brio entre F1-Score, precisÃ£o e recall**, priorizando a capacidade do modelo em evitar **erros crÃ­ticos** para o sistema de irrigaÃ§Ã£o.

---

### Justificativa a ser adicionada apÃ³s os testes

**ApÃ³s a execuÃ§Ã£o dos testes, o algoritmo com melhor desempenho foi o:**

 **Random Forest Classifier** com F1-Score: 
 **Precision**: 
 **Recall**: 

O Random Forest foi escolhido como modelo final pois apresentou o melhor equilÃ­brio entre precisÃ£o e recall, alÃ©m de ser robusto contra overfitting e fornecer uma boa explicabilidade atravÃ©s das importÃ¢ncias das features.

---

### ConsideraÃ§Ãµes Finais

Essa abordagem de testar mÃºltiplos algoritmos garante uma escolha **baseada em dados**, e nÃ£o apenas em suposiÃ§Ãµes teÃ³ricas. AlÃ©m disso, o pipeline criado Ã© facilmente reutilizÃ¡vel e extensÃ­vel para novas versÃµes do sistema.


---


5. **OtimizaÃ§Ã£o**

   * AplicaÃ§Ã£o de **Grid Search** e/ou **Random Search** para ajuste de hiperparÃ¢metros.
   * Escolha do modelo com melhor desempenho.

6. **AvaliaÃ§Ã£o**

   * AvaliaÃ§Ã£o final com mÃ©tricas:

     * AcurÃ¡cia
     * PrecisÃ£o
     * Recall
     * F1-score
     * Matriz de confusÃ£o
   * AnÃ¡lise de erros e limitaÃ§Ãµes.

7. **ImplantaÃ§Ã£o (Deploy)**

   * Desenvolvimento de um **dashboard interativo com Streamlit**.
   * Interface grÃ¡fica amigÃ¡vel para utilizaÃ§Ã£o do modelo.
   * (Opcional) IntegraÃ§Ã£o com banco de dados para armazenar resultados.

---

## ğŸ—ï¸ **Estrutura do Projeto (Arquitetura de Pastas)**

```
Classificacao-Graos-ML/
â”œâ”€â”€ ğŸ“ dados/
â”‚   â”œâ”€â”€ seeds_dataset.csv
â”‚   â””â”€â”€ dados_tratados.csv
â”œâ”€â”€ ğŸ“ notebooks/
â”‚   â”œâ”€â”€ 1_analise_exploratoria.ipynb
â”‚   â”œâ”€â”€ 2_modelagem.ipynb
â”‚   â”œâ”€â”€ 3_otimizacao.ipynb
â”‚   â””â”€â”€ 4_dashboard_streamlit.ipynb
â”œâ”€â”€ ğŸ“ modelos/
â”‚   â””â”€â”€ modelo_final.pkl
â”œâ”€â”€ ğŸ“ dashboard_streamlit/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ model.pkl
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ ğŸ“ imagens/
â”‚   â”œâ”€â”€ boxplot.png
â”‚   â”œâ”€â”€ heatmap_correlacao.png
â”‚   â”œâ”€â”€ matriz_confusao.png
â”‚   â”œâ”€â”€ scatterplot.png
â”‚   â””â”€â”€ dashboard.png
â”œâ”€â”€ ğŸ“ banco_de_dados/
â”‚   â””â”€â”€ modelo_banco.sql
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

## ğŸš¦ **Kanban de OrganizaÃ§Ã£o (SugestÃ£o)**

### ğŸ”§ **Backlog**

* Download e organizaÃ§Ã£o do dataset.
* Definir escopo completo e arquitetura de dados.
* Levantamento dos requisitos do dashboard e funcionalidades.

### ğŸ§  **Design**

* Criar fluxograma da soluÃ§Ã£o.
* Desenhar o layout do dashboard Streamlit.
* Planejar a estrutura de notebooks, modelos e banco de dados.

### ğŸš€ **A Fazer**

* Realizar anÃ¡lise exploratÃ³ria dos dados.
* Tratar dados (outliers, normalizaÃ§Ã£o).
* Implementar modelos (KNN, SVM, Random Forest).
* Avaliar e comparar modelos.
* Realizar otimizaÃ§Ã£o dos hiperparÃ¢metros.
* Exportar modelo final treinado (.pkl).
* Criar dashboard interativo no Streamlit.
* Desenvolver banco de dados (opcional).
* Documentar todo o projeto no README.
* Gravar vÃ­deo de apresentaÃ§Ã£o.

### âœ… **Feito**

* Tarefas concluÃ­das.

---

## ğŸ§  **Insights Esperados**

1. **Insight TÃ©cnico:**
   Avaliar quais caracterÃ­sticas dos grÃ£os sÃ£o mais relevantes para a classificaÃ§Ã£o. Identificar padrÃµes que poderiam passar despercebidos na anÃ¡lise manual, como correlaÃ§Ãµes entre Ã¡rea, compacidade e comprimento do sulco.

2. **Insight Operacional:**
   Demonstrar que Ã© possÃ­vel implementar uma soluÃ§Ã£o acessÃ­vel, barata e eficiente que automatiza um processo tradicionalmente manual, democratizando o acesso Ã  inteligÃªncia artificial no setor agrÃ­cola, especialmente para pequenas e mÃ©dias cooperativas.

---

## ğŸš€ **Impacto Final**

Ao final deste projeto, as cooperativas e produtores terÃ£o acesso a uma ferramenta capaz de:

* Reduzir o tempo de classificaÃ§Ã£o dos grÃ£os;
* Aumentar a precisÃ£o e consistÃªncia dos resultados;
* Melhorar a eficiÃªncia dos processos agrÃ­colas;
* Facilitar a integraÃ§Ã£o de inteligÃªncia artificial no campo.

## **ReferÃªncias**

[1] Charytanowicz, M., Niewczas, J., Kulczycki, P., Kowalski, P., & Lukasik, S. (2010). Seeds [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C5H30K.
