FIAP - Faculdade de Inform√°tica e Administra√ß√£o Paulista 

<p align="center">
<a href= "https://www.fiap.com.br/"><img src="assets/logo-fiap.png" alt="FIAP - Faculdade de Inform√°tica e Admnistra√ß√£o Paulista" border="0" width=40% height=40%></a>
</p>

<br>

# üåæ  Da Terra ao C√≥digo ‚Äî Automatizando a Classifica√ß√£o de Gr√£os com Machine Learning

## Nome do grupo

## üë®‚Äçüéì Integrantes: 
- <a href="https://www.linkedin.com/in/antoniobarros99/">Antonio Ancelmo Neto Barros </a>
- <a>Beatriz pilecaarte de Melo 
- <a>Francismar Alves Martins Junior </a> 
- <a href="https://https://www.linkedin.com/in/vitor-eiji/">Vitor Eiji Fernandes Teruia</a> 
- <a href="https://www.linkedin.com/in/matheus-soares04">Matheus Soares Bento da Silva</a>

## üë©‚Äçüè´ Professores:
### Tutor(a) 
- <a href="https://www.linkedin.com/in/leonardoorabona/">Leo Ruiz</a>
### Coordenador(a)
- <a href="https://www.linkedin.com/company/inova-fusca">Andr√© Godoi</a>

--- 

## üìú Descri√ß√£o

A classifica√ß√£o de gr√£os √© uma etapa fundamental no controle de qualidade dentro da cadeia produtiva agr√≠cola. Atualmente, em muitas cooperativas de pequeno e m√©dio porte, esse processo ainda √© realizado de forma manual por especialistas, utilizando inspe√ß√£o visual e ferramentas simples. Isso gera desafios como alta demanda de tempo, custos operacionais elevados e poss√≠veis erros humanos, afetando diretamente a efici√™ncia e a qualidade do produto final.

Este projeto tem como foco o desenvolvimento de um sistema inteligente capaz de realizar a **classifica√ß√£o autom√°tica de gr√£os de trigo** com base em suas caracter√≠sticas f√≠sicas. A solu√ß√£o utiliza algoritmos de **Machine Learning** aplicados ao **"Seeds Dataset"** do UCI Machine Learning Repository, com amostras de tr√™s tipos de trigo: **Kama, Rosa e Canadian**.

Al√©m do desenvolvimento dos modelos, ser√° criado um **dashboard interativo utilizando Streamlit**, que permitir√° que qualquer usu√°rio ‚Äî mesmo sem conhecimento t√©cnico ‚Äî possa realizar classifica√ß√µes, visualizar an√°lises e extrair informa√ß√µes √∫teis sobre os gr√£os analisados.

---

## ‚úÖ **Justificativa**

O desenvolvimento deste projeto se justifica pela necessidade crescente de **automatizar processos agr√≠colas**, tornando-os mais precisos, eficientes e acess√≠veis, especialmente para pequenos produtores e cooperativas.

### üí° **Por que √© necess√°rio?**

* Processos manuais est√£o sujeitos a erros e inconsist√™ncias.
* Reduz o custo com m√£o de obra especializada.
* Aumenta a produtividade e padroniza√ß√£o na classifica√ß√£o.
* Traz acessibilidade √† tecnologia de an√°lise de dados no campo.

### üåé **Impacto Esperado**

* Moderniza√ß√£o das pr√°ticas agr√≠colas.
* Redu√ß√£o de custos operacionais.
* Tomada de decis√£o mais assertiva.
* Contribui√ß√£o para a transforma√ß√£o digital no agroneg√≥cio.
* 
---

## üî¨ **Metodologia ‚Äî CRISP-DM**

O projeto segue as etapas da metodologia **CRISP-DM (Cross Industry Standard Process for Data Mining)**, amplamente utilizada para desenvolvimento de projetos de ci√™ncia de dados.

### üö¶ **Etapas:**

1. **Entendimento do Neg√≥cio**

#### Fluxo de Dados

1. O dataset original est√° em formato `.txt`.
2. Os dados ser√£o carregados em mem√≥ria com `pandas` para pr√©-processamento.
3. Ap√≥s o tratamento, o dataset limpo ser√° salvo em `.csv`.
4. Os dados tratados ser√£o usados para:
   - Treinamento de modelos de Machine Learning.
   - An√°lises estat√≠sticas.
   - Visualiza√ß√µes.

#### Estrutura de Dados

| Coluna | Descri√ß√£o |
|--------|----------|
| area | √Årea da semente |
| perimeter | Per√≠metro |
| compactness | Compacidade |
| kernel_length | Comprimento do gr√£o |
| kernel_width | Largura do gr√£o |
| asymmetry | Coeficiente de assimetria |
| kernel_groove | Comprimento do sulco do gr√£o |
| class | Classe (1, 2 ou 3) |

#### Armazenamento

- **Dados brutos**: txt
- **Dados tratados**: txt limpo
- **Modelos**: arquivos `.pkl` ou similares
- **Resultados**: 

#### Banco de Dados

- Decidiu-se utilizar **txt** como estrutura de armazenamento.


2. **Entendimento dos Dados**

   * An√°lise do dataset "Seeds Dataset".
   * Compreens√£o das vari√°veis:

     * √Årea, Per√≠metro, Compacidade, Comprimento do N√∫cleo, Largura do N√∫cleo, Coeficiente de Assimetria, Comprimento do Sulco.

3. **Prepara√ß√£o dos Dados**

   * Verifica√ß√£o de valores ausentes.
   * Detec√ß√£o e tratamento de outliers.
   * Normaliza√ß√£o ou padroniza√ß√£o dos dados.
   * Cria√ß√£o de visualiza√ß√µes (boxplots, histogramas, scatterplots, heatmap de correla√ß√£o).

4. ## üìà Machine Learning

###  Escolha e Avalia√ß√£o de Algoritmos

Para esta fase do projeto, decidimos realizar o **treinamento e avalia√ß√£o com m√∫ltiplos algoritmos** de Machine Learning, com o objetivo de identificar aquele que oferece o melhor desempenho para o problema de **prever a necessidade de irriga√ß√£o**.

O problema foi modelado como uma **classifica√ß√£o bin√°ria**, onde o modelo deve prever se a irriga√ß√£o √© necess√°ria (`1`) ou n√£o (`0`), com base em vari√°veis como umidade do solo, n√≠veis de nutrientes, temperatura e hora do dia.

---

### Algoritmos Avaliados

| Algoritmo                                  | Vantagens                                                              | Desvantagens                                              |
| ------------------------------------------ | ---------------------------------------------------------------------- | --------------------------------------------------------- |
| **Logistic Regression**                    | Simples, r√°pido, bom para baseline                                     | Sup√µe rela√ß√£o linear entre as vari√°veis                   |
| **Decision Tree**                          | F√°cil de interpretar, lida com vari√°veis categ√≥ricas                   | Pode sofrer de overfitting e ser sens√≠vel a ru√≠do         |
| **Random Forest**                          | Reduz overfitting, boa acur√°cia, robusto                               | Mais lento e menos interpret√°vel que uma √°rvore √∫nica     |
| **K-Nearest Neighbors (KNN)**              | Simples, n√£o-param√©trico, intuitivo                                    | Custo computacional elevado em grandes conjuntos de dados |
| **Support Vector Machine (SVM)**           | Eficaz em espa√ßos de alta dimens√£o, bom para problemas complexos       | Mais lento e exige ajuste cuidadoso de par√¢metros         |
| **Gradient Boosting (LightGBM, CatBoost)** | Alta performance, lida bem com n√£o-linearidades e dados desbalanceados | Complexidade maior e menos interpret√°vel                  |

---

### Metodologia

Todos os algoritmos foram treinados utilizando a biblioteca **Scikit-learn** (com exce√ß√£o do **LightGBM** e **CatBoost**, implementados com suas respectivas bibliotecas).

O dataset foi dividido em **80% para treino** e **20% para teste** utilizando **stratified split** para manter a propor√ß√£o das classes.

O pr√©-processamento incluiu:

* Normaliza√ß√£o das vari√°veis num√©ricas para algoritmos sens√≠veis a escala (KNN, SVM).
* Convers√£o de vari√°veis categ√≥ricas, se houver.
* Tratamento de dados ausentes.

---

### M√©tricas de Avalia√ß√£o

Para comparar os modelos, utilizamos as seguintes m√©tricas:

| M√©trica                | Justificativa                                                |
| ---------------------- | ------------------------------------------------------------ |
| **Acur√°cia**           | Percentual de acertos gerais                                 |
| **Precis√£o**           | Evitar falsos positivos: irrigar desnecessariamente          |
| **Recall**             | Evitar falsos negativos: falhar em irrigar quando necess√°rio |
| **F1-Score**           | M√©trica principal para balancear precis√£o e recall           |
| **Matriz de Confus√£o** | An√°lise visual dos erros de cada modelo                      |

**Obs.:** Se o dataset apresentar **desbalanceamento** entre classes, as m√©tricas como **F1-Score** e **Recall** ter√£o maior peso na decis√£o final.

---

### Processo de Treinamento

Para cada modelo, seguimos o mesmo pipeline:

1. Separa√ß√£o de **features** e **target**.
2. Divis√£o em **treino** e **teste**.
3. Ajuste de **par√¢metros padr√£o** (sem hiperpar√¢metros complexos, para avalia√ß√£o justa).
4. Treinamento do modelo.
5. Avalia√ß√£o com as m√©tricas definidas.

---

### Exemplo de C√≥digo para Avalia√ß√£o de Todos os Modelos

```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC

import lightgbm as lgb
from catboost import CatBoostClassifier

# Separa√ß√£o
X = df[['umidade', 'nutrientes', 'temperatura', 'hora_dia']]
y = df['precisa_irrigar']

# Divis√£o
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Normaliza√ß√£o
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Modelos
models = {
    'Logistic Regression': LogisticRegression(),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'KNN': KNeighborsClassifier(),
    'SVM': SVC(probability=True),
    'LightGBM': lgb.LGBMClassifier(),
    'CatBoost': CatBoostClassifier(verbose=0)
}

# Treinamento e avalia√ß√£o
for name, model in models.items():
    if name in ['KNN', 'SVM', 'Logistic Regression']:
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
    else:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

    print(f"\nModelo: {name}")
    print(classification_report(y_test, y_pred))
    print("Matriz de Confus√£o:")
    print(confusion_matrix(y_test, y_pred))
```

---

###  Defini√ß√£o do Algoritmo Final

Ap√≥s realizar a avalia√ß√£o com todos os modelos e comparar os resultados com base nas m√©tricas definidas, selecionaremos como **algoritmo final** aquele que apresentar o **melhor equil√≠brio entre F1-Score, precis√£o e recall**, priorizando a capacidade do modelo em evitar **erros cr√≠ticos** para o sistema de irriga√ß√£o.

---

### Justificativa a ser adicionada ap√≥s os testes

**Ap√≥s a execu√ß√£o dos testes, o algoritmo com melhor desempenho foi o:**

 **Random Forest Classifier** com F1-Score: 
 **Precision**: 
 **Recall**: 

O Random Forest foi escolhido como modelo final pois apresentou o melhor equil√≠brio entre precis√£o e recall, al√©m de ser robusto contra overfitting e fornecer uma boa explicabilidade atrav√©s das import√¢ncias das features.

---

### Considera√ß√µes Finais

Essa abordagem de testar m√∫ltiplos algoritmos garante uma escolha **baseada em dados**, e n√£o apenas em suposi√ß√µes te√≥ricas. Al√©m disso, o pipeline criado √© facilmente reutiliz√°vel e extens√≠vel para novas vers√µes do sistema.

---


## üìÅ Estrutura de pastas
```
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îî‚îÄ‚îÄ requisitos_dashboard
‚îú‚îÄ‚îÄ dados/
‚îÇ   ‚îú‚îÄ‚îÄ processados/
‚îÇ   ‚îî‚îÄ‚îÄ seeds_tratado.csv
‚îú‚îÄ‚îÄ doc/
‚îÇ   ‚îú‚îÄ‚îÄ arquitetura_dados.md
‚îÇ   ‚îî‚îÄ‚îÄ notebooks/
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ requirements.txt
```
## üîß Como executar o c√≥digo

### 1. Clonar o reposit√≥rio

```
git clone https://github.com/seu-usuario/seu-repositorio.git
```
### 2. crie um ambiene virtual (opcional, mas recomendado)
```
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
.venv\Scripts\activate     # Windows
```
### 3. instalar as dependencias
```
pip install -r requirements.txt
```
### 4. executar os notebooks
```
jupyter notebook notebooks/
```
### 5. executar o dashboard
```
streamlit run app/dashboard_streamlit/app.py
```

## üóÉ Hist√≥rico de lan√ßamentos
     
* 0.1.0 - 19/06/2025
    *

## üìã Licen√ßa

<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><a property="dct:title" rel="cc:attributionURL" href="https://github.com/agodoi/template">MODELO GIT FIAP</a> por <a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://fiap.com.br">Fiap</a> est√° licenciado sobre <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">Attribution 4.0 International</a>.</p>
