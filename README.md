# Cap3-ImplementandoalgoritmosdeMachineLearningcomScikitlearn
A classifica√ß√£o de gr√£os √© uma etapa fundamental no controle de qualidade dentro da cadeia produtiva agr√≠cola. Atualmente, em muitas cooperativas de pequeno e m√©dio porte, esse processo ainda √© realizado de forma manual por especialistas, utilizando inspe√ß√£o visual e ferramentas simples.

---

# üåæ **Projeto: Da Terra ao C√≥digo ‚Äî Automatizando a Classifica√ß√£o de Gr√£os com Machine Learning**

---

## üìÑ **Descri√ß√£o do Projeto**

A classifica√ß√£o de gr√£os √© uma etapa fundamental no controle de qualidade dentro da cadeia produtiva agr√≠cola. Atualmente, em muitas cooperativas de pequeno e m√©dio porte, esse processo ainda √© realizado de forma manual por especialistas, utilizando inspe√ß√£o visual e ferramentas simples. Isso gera desafios como alta demanda de tempo, custos operacionais elevados e poss√≠veis erros humanos, afetando diretamente a efici√™ncia e a qualidade do produto final.

Este projeto tem como foco o desenvolvimento de um sistema inteligente capaz de realizar a **classifica√ß√£o autom√°tica de gr√£os de trigo** com base em suas caracter√≠sticas f√≠sicas. A solu√ß√£o utiliza algoritmos de **Machine Learning** aplicados ao **"Seeds Dataset"** do UCI Machine Learning Repository, com amostras de tr√™s tipos de trigo: **Kama, Rosa e Canadian**.

Al√©m do desenvolvimento dos modelos, ser√° criado um **dashboard interativo utilizando Streamlit**, que permitir√° que qualquer usu√°rio ‚Äî mesmo sem conhecimento t√©cnico ‚Äî possa realizar classifica√ß√µes, visualizar an√°lises e extrair informa√ß√µes √∫teis sobre os gr√£os analisados.

---

## ‚úÖ **Justificativa**

O desenvolvimento deste projeto se justifica pela necessidade crescente de **automatizar processos agr√≠colas**, tornando-os mais precisos, eficientes e acess√≠veis, especialmente para pequenos produtores e cooperativas.

### üí° **Por que √© necess√°rio?**

* Processos manuais est√£o sujeitos a erros e inconsist√™ncias.
* Reduz o custo com m√£o de obra especializada.
* Aumenta a produtividade e padroniza√ß√£o na classifica√ß√£o.
* Traz acessibilidade √† tecnologia de an√°lise de dados no campo.

### üåé **Impacto Esperado**

* Moderniza√ß√£o das pr√°ticas agr√≠colas.
* Redu√ß√£o de custos operacionais.
* Tomada de decis√£o mais assertiva.
* Contribui√ß√£o para a transforma√ß√£o digital no agroneg√≥cio.

---

## üéØ **Objetivos**

### üîπ **Objetivo Geral**

Desenvolver uma solu√ß√£o baseada em Machine Learning capaz de classificar gr√£os de trigo automaticamente a partir de suas caracter√≠sticas f√≠sicas, utilizando um dashboard interativo para facilitar a utiliza√ß√£o pelos usu√°rios.

### üî∏ **Objetivos Espec√≠ficos**

* Realizar an√°lise explorat√≥ria e pr√©-processamento dos dados.
* Implementar e comparar diferentes modelos de classifica√ß√£o.
* Otimizar os modelos para aumentar a acur√°cia e a robustez.
* Avaliar os modelos utilizando m√©tricas como acur√°cia, precis√£o, recall, F1-score e matriz de confus√£o.
* Desenvolver um dashboard interativo que permita a utiliza√ß√£o do modelo de classifica√ß√£o.
* Documentar todo o processo no GitHub com c√≥digo, relat√≥rios e arquivos auxiliares.

---

## üî¨ **Metodologia ‚Äî CRISP-DM**

O projeto segue as etapas da metodologia **CRISP-DM (Cross Industry Standard Process for Data Mining)**, amplamente utilizada para desenvolvimento de projetos de ci√™ncia de dados.

### üö¶ **Etapas:**

1. **Entendimento do Neg√≥cio**

#### Fluxo de Dados

1. O dataset original est√° em formato `.txt`.
2. Os dados ser√£o carregados em mem√≥ria com `pandas` para pr√©-processamento.
3. Ap√≥s o tratamento, o dataset limpo ser√° salvo em `.csv`.
4. Os dados tratados ser√£o usados para:
   - Treinamento de modelos de Machine Learning.
   - An√°lises estat√≠sticas.
   - Visualiza√ß√µes.

#### Estrutura de Dados

| Coluna | Descri√ß√£o |
|--------|----------|
| area | √Årea da semente |
| perimeter | Per√≠metro |
| compactness | Compacidade |
| kernel_length | Comprimento do gr√£o |
| kernel_width | Largura do gr√£o |
| asymmetry | Coeficiente de assimetria |
| kernel_groove | Comprimento do sulco do gr√£o |
| class | Classe (1, 2 ou 3) |

#### Armazenamento

- **Dados brutos**: txt
- **Dados tratados**: txt limpo
- **Modelos**: arquivos `.pkl` ou similares
- **Resultados**: 

#### Banco de Dados

- Decidiu-se utilizar **txt** como estrutura de armazenamento.


2. **Entendimento dos Dados**

   * An√°lise do dataset "Seeds Dataset".
   * Compreens√£o das vari√°veis:

     * √Årea, Per√≠metro, Compacidade, Comprimento do N√∫cleo, Largura do N√∫cleo, Coeficiente de Assimetria, Comprimento do Sulco.

3. **Prepara√ß√£o dos Dados**

   * Verifica√ß√£o de valores ausentes.
   * Detec√ß√£o e tratamento de outliers.
   * Normaliza√ß√£o ou padroniza√ß√£o dos dados.
   * Cria√ß√£o de visualiza√ß√µes (boxplots, histogramas, scatterplots, heatmap de correla√ß√£o).

4. ## üìà Machine Learning

###  Escolha e Avalia√ß√£o de Algoritmos

Para esta fase do projeto, decidimos realizar o **treinamento e avalia√ß√£o com m√∫ltiplos algoritmos** de Machine Learning, com o objetivo de identificar aquele que oferece o melhor desempenho para o problema de **prever a necessidade de irriga√ß√£o**.

O problema foi modelado como uma **classifica√ß√£o bin√°ria**, onde o modelo deve prever se a irriga√ß√£o √© necess√°ria (`1`) ou n√£o (`0`), com base em vari√°veis como umidade do solo, n√≠veis de nutrientes, temperatura e hora do dia.

---

### Algoritmos Avaliados

| Algoritmo                                  | Vantagens                                                              | Desvantagens                                              |
| ------------------------------------------ | ---------------------------------------------------------------------- | --------------------------------------------------------- |
| **Logistic Regression**                    | Simples, r√°pido, bom para baseline                                     | Sup√µe rela√ß√£o linear entre as vari√°veis                   |
| **Decision Tree**                          | F√°cil de interpretar, lida com vari√°veis categ√≥ricas                   | Pode sofrer de overfitting e ser sens√≠vel a ru√≠do         |
| **Random Forest**                          | Reduz overfitting, boa acur√°cia, robusto                               | Mais lento e menos interpret√°vel que uma √°rvore √∫nica     |
| **K-Nearest Neighbors (KNN)**              | Simples, n√£o-param√©trico, intuitivo                                    | Custo computacional elevado em grandes conjuntos de dados |
| **Support Vector Machine (SVM)**           | Eficaz em espa√ßos de alta dimens√£o, bom para problemas complexos       | Mais lento e exige ajuste cuidadoso de par√¢metros         |
| **Gradient Boosting (LightGBM, CatBoost)** | Alta performance, lida bem com n√£o-linearidades e dados desbalanceados | Complexidade maior e menos interpret√°vel                  |

---

### Metodologia

Todos os algoritmos foram treinados utilizando a biblioteca **Scikit-learn** (com exce√ß√£o do **LightGBM** e **CatBoost**, implementados com suas respectivas bibliotecas).

O dataset foi dividido em **80% para treino** e **20% para teste** utilizando **stratified split** para manter a propor√ß√£o das classes.

O pr√©-processamento incluiu:

* Normaliza√ß√£o das vari√°veis num√©ricas para algoritmos sens√≠veis a escala (KNN, SVM).
* Convers√£o de vari√°veis categ√≥ricas, se houver.
* Tratamento de dados ausentes.

---

### M√©tricas de Avalia√ß√£o

Para comparar os modelos, utilizamos as seguintes m√©tricas:

| M√©trica                | Justificativa                                                |
| ---------------------- | ------------------------------------------------------------ |
| **Acur√°cia**           | Percentual de acertos gerais                                 |
| **Precis√£o**           | Evitar falsos positivos: irrigar desnecessariamente          |
| **Recall**             | Evitar falsos negativos: falhar em irrigar quando necess√°rio |
| **F1-Score**           | M√©trica principal para balancear precis√£o e recall           |
| **Matriz de Confus√£o** | An√°lise visual dos erros de cada modelo                      |

**Obs.:** Se o dataset apresentar **desbalanceamento** entre classes, as m√©tricas como **F1-Score** e **Recall** ter√£o maior peso na decis√£o final.

---

### Processo de Treinamento

Para cada modelo, seguimos o mesmo pipeline:

1. Separa√ß√£o de **features** e **target**.
2. Divis√£o em **treino** e **teste**.
3. Ajuste de **par√¢metros padr√£o** (sem hiperpar√¢metros complexos, para avalia√ß√£o justa).
4. Treinamento do modelo.
5. Avalia√ß√£o com as m√©tricas definidas.

---

### Exemplo de C√≥digo para Avalia√ß√£o de Todos os Modelos

```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC

import lightgbm as lgb
from catboost import CatBoostClassifier

# Separa√ß√£o
X = df[['umidade', 'nutrientes', 'temperatura', 'hora_dia']]
y = df['precisa_irrigar']

# Divis√£o
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Normaliza√ß√£o
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Modelos
models = {
    'Logistic Regression': LogisticRegression(),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'KNN': KNeighborsClassifier(),
    'SVM': SVC(probability=True),
    'LightGBM': lgb.LGBMClassifier(),
    'CatBoost': CatBoostClassifier(verbose=0)
}

# Treinamento e avalia√ß√£o
for name, model in models.items():
    if name in ['KNN', 'SVM', 'Logistic Regression']:
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
    else:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

    print(f"\nModelo: {name}")
    print(classification_report(y_test, y_pred))
    print("Matriz de Confus√£o:")
    print(confusion_matrix(y_test, y_pred))
```

---

###  Defini√ß√£o do Algoritmo Final

Ap√≥s realizar a avalia√ß√£o com todos os modelos e comparar os resultados com base nas m√©tricas definidas, selecionaremos como **algoritmo final** aquele que apresentar o **melhor equil√≠brio entre F1-Score, precis√£o e recall**, priorizando a capacidade do modelo em evitar **erros cr√≠ticos** para o sistema de irriga√ß√£o.

---

### Justificativa a ser adicionada ap√≥s os testes

**Ap√≥s a execu√ß√£o dos testes, o algoritmo com melhor desempenho foi o:**

 **Random Forest Classifier** com F1-Score: 
 **Precision**: 
 **Recall**: 

O Random Forest foi escolhido como modelo final pois apresentou o melhor equil√≠brio entre precis√£o e recall, al√©m de ser robusto contra overfitting e fornecer uma boa explicabilidade atrav√©s das import√¢ncias das features.

---

### Considera√ß√µes Finais

Essa abordagem de testar m√∫ltiplos algoritmos garante uma escolha **baseada em dados**, e n√£o apenas em suposi√ß√µes te√≥ricas. Al√©m disso, o pipeline criado √© facilmente reutiliz√°vel e extens√≠vel para novas vers√µes do sistema.


---


5. **Otimiza√ß√£o**

   * Aplica√ß√£o de **Grid Search** e/ou **Random Search** para ajuste de hiperpar√¢metros.
   * Escolha do modelo com melhor desempenho.

6. **Avalia√ß√£o**

   * Avalia√ß√£o final com m√©tricas:

     * Acur√°cia
     * Precis√£o
     * Recall
     * F1-score
     * Matriz de confus√£o
   * An√°lise de erros e limita√ß√µes.

7. **Implanta√ß√£o (Deploy)**

   * Desenvolvimento de um **dashboard interativo com Streamlit**.
   * Interface gr√°fica amig√°vel para utiliza√ß√£o do modelo.
   * (Opcional) Integra√ß√£o com banco de dados para armazenar resultados.

---

## üèóÔ∏è **Estrutura do Projeto (Arquitetura de Pastas)**

```
Classificacao-Graos-ML/
‚îú‚îÄ‚îÄ üìÅ dados/
‚îÇ   ‚îú‚îÄ‚îÄ seeds_dataset.csv
‚îÇ   ‚îî‚îÄ‚îÄ dados_tratados.csv
‚îú‚îÄ‚îÄ üìÅ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 1_analise_exploratoria.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 2_modelagem.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 3_otimizacao.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 4_dashboard_streamlit.ipynb
‚îú‚îÄ‚îÄ üìÅ modelos/
‚îÇ   ‚îî‚îÄ‚îÄ modelo_final.pkl
‚îú‚îÄ‚îÄ üìÅ dashboard_streamlit/
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îú‚îÄ‚îÄ model.pkl
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ üìÅ imagens/
‚îÇ   ‚îú‚îÄ‚îÄ boxplot.png
‚îÇ   ‚îú‚îÄ‚îÄ heatmap_correlacao.png
‚îÇ   ‚îú‚îÄ‚îÄ matriz_confusao.png
‚îÇ   ‚îú‚îÄ‚îÄ scatterplot.png
‚îÇ   ‚îî‚îÄ‚îÄ dashboard.png
‚îú‚îÄ‚îÄ üìÅ banco_de_dados/
‚îÇ   ‚îî‚îÄ‚îÄ modelo_banco.sql
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ LICENSE
```

---

## üö¶ **Kanban de Organiza√ß√£o (Sugest√£o)**

### üîß **Backlog**

* Download e organiza√ß√£o do dataset.
* Definir escopo completo e arquitetura de dados.
* Levantamento dos requisitos do dashboard e funcionalidades.

### üß† **Design**

* Criar fluxograma da solu√ß√£o.
* Desenhar o layout do dashboard Streamlit.
* Planejar a estrutura de notebooks, modelos e banco de dados.

### üöÄ **A Fazer**

* Realizar an√°lise explorat√≥ria dos dados.
* Tratar dados (outliers, normaliza√ß√£o).
* Implementar modelos (KNN, SVM, Random Forest).
* Avaliar e comparar modelos.
* Realizar otimiza√ß√£o dos hiperpar√¢metros.
* Exportar modelo final treinado (.pkl).
* Criar dashboard interativo no Streamlit.
* Desenvolver banco de dados (opcional).
* Documentar todo o projeto no README.
* Gravar v√≠deo de apresenta√ß√£o.

### ‚úÖ **Feito**

* Tarefas conclu√≠das.

---

## üß† **Insights Esperados**

1. **Insight T√©cnico:**
   Avaliar quais caracter√≠sticas dos gr√£os s√£o mais relevantes para a classifica√ß√£o. Identificar padr√µes que poderiam passar despercebidos na an√°lise manual, como correla√ß√µes entre √°rea, compacidade e comprimento do sulco.

2. **Insight Operacional:**
   Demonstrar que √© poss√≠vel implementar uma solu√ß√£o acess√≠vel, barata e eficiente que automatiza um processo tradicionalmente manual, democratizando o acesso √† intelig√™ncia artificial no setor agr√≠cola, especialmente para pequenas e m√©dias cooperativas.

---

## üöÄ **Impacto Final**

Ao final deste projeto, as cooperativas e produtores ter√£o acesso a uma ferramenta capaz de:

* Reduzir o tempo de classifica√ß√£o dos gr√£os;
* Aumentar a precis√£o e consist√™ncia dos resultados;
* Melhorar a efici√™ncia dos processos agr√≠colas;
* Facilitar a integra√ß√£o de intelig√™ncia artificial no campo.

## **Refer√™ncias**

[1] Charytanowicz, M., Niewczas, J., Kulczycki, P., Kowalski, P., & Lukasik, S. (2010). Seeds [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C5H30K.
